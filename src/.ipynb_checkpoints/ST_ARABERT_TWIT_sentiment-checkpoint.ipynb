{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4acc29-d8ec-4544-868e-a726e26b978d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import datasets\n",
    "from datasets import ClassLabel, load_dataset, Dataset, DatasetDict, concatenate_datasets\n",
    "import string\n",
    "from typing import Dict ,List\n",
    "import transformers\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AdamW\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfe92d48-4226-4e51-87e6-c23ac0de341d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/gufran/Developer/Projects/AI/MawqifStanceDetection/data\"\n",
    "MODEL_PATH = \"/Users/gufran/Developer/Projects/AI/MawqifStanceDetection/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "592da9a1-ca5c-48f1-912e-af2b16a0d3fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"aubmindlab/bert-base-arabertv02-twitter\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a8546e-1c06-4598-9bb1-001e2119d485",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>لخسارة وزنك بشكل طبيعي ما الك غير مجموعة كلين ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>لا يكلف الله نفسا إلا وسعها 🌹</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وكل السعوديه بدو ..حتى الحاضره منهم من اصل بدو...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>المونافري طلع برهوش .. سدينا 😤</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>منو خر بيتهم مثلنا 😩</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  لخسارة وزنك بشكل طبيعي ما الك غير مجموعة كلين ...  Negative\n",
       "1                      لا يكلف الله نفسا إلا وسعها 🌹  Positive\n",
       "2  وكل السعوديه بدو ..حتى الحاضره منهم من اصل بدو...  Negative\n",
       "3                     المونافري طلع برهوش .. سدينا 😤  Negative\n",
       "4                               منو خر بيتهم مثلنا 😩  Negative"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_supp = pd.read_csv(os.path.join(DATA_PATH, \"ASTAD_train.csv\"))\n",
    "df_supp = df_supp[[\"text\", \"sentiment\"]]\n",
    "df_supp = df_supp.sample(frac=1, random_state=42)\n",
    "df_supp = df_supp.reset_index().drop([\"index\"], axis=1)\n",
    "df_supp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f9f3daf-10fc-431b-b629-e50d5cf953dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>عشان يلمع صورته ويعنني تمكين المرأة ويصير ترن...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>روح حلل محد يم تطعيم كورونا شف الحرم البارح م...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>هذا ما يُعرّف بـ'فوبيا المرأة المُتمكنة' آفة ف...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#LEAP22  مؤتمر يجمع اشهر وابرز المؤثرين في الم...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>خصوصية البيانات وحمايتها في المنظمة مطلب ولكن ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0   عشان يلمع صورته ويعنني تمكين المرأة ويصير ترن...  Negative\n",
       "1   روح حلل محد يم تطعيم كورونا شف الحرم البارح م...   Neutral\n",
       "2  هذا ما يُعرّف بـ'فوبيا المرأة المُتمكنة' آفة ف...  Negative\n",
       "3  #LEAP22  مؤتمر يجمع اشهر وابرز المؤثرين في الم...  Positive\n",
       "4  خصوصية البيانات وحمايتها في المنظمة مطلب ولكن ...   Neutral"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"cleaned.csv\"))\n",
    "df = df[[\"text\", \"sentiment\"]]\n",
    "df = df.dropna(subset=[\"sentiment\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29fc1c62-c109-4f79-a26c-ba3da4424db8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Neutral', 'Positive'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b721a997-bd9c-498e-b6b2-12ebb98f3811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping_sentiment = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
    "df['label'] = df['sentiment'].map(lambda x: mapping_sentiment[x])\n",
    "df_supp['label'] = df_supp['sentiment'].map(lambda x: mapping_sentiment[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a11cd7a-02ef-49e0-9b53-2f0125954e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arabic_punctuations = '''`÷×؛<>()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "\n",
    "def remove_hash_URL_MEN(text):\n",
    "    text = re.sub(r'#',' ',text)\n",
    "    text = re.sub(r'_',' ',text)\n",
    "    text = re.sub(r'URL','',text)\n",
    "    text = re.sub(r'MENTION','',text)\n",
    "    return text\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    text = re.sub(\"[إآ]\", \"ا\", text)\n",
    "    text = re.sub(\"گ\", \"ك\", text)\n",
    "    return text\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "def remove_repeating_char(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "\n",
    "def process_tweet(tweet):     \n",
    "    tweet=remove_hash_URL_MEN(tweet)\n",
    "    tweet = re.sub('@[^\\s]+', ' ', str(tweet))\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',str(tweet))    \n",
    "    tweet= normalize_arabic(str(tweet))\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
    "df.text = df.text.apply(lambda x: process_tweet(x))\n",
    "df.text = df.text.apply(lambda x: arabert_prep.preprocess(x))\n",
    "\n",
    "df_supp.text = df_supp.text.apply(lambda x: process_tweet(x))\n",
    "df_supp.text = df_supp.text.apply(lambda x: arabert_prep.preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb2fce5-cf31-43f1-b258-3a86e888f5d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>عشان يلمع صورته ويعنني تمكين المرأة ويصير ترند...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>روح حلل محد يم تطعيم كورونا شف الحرم البارح مل...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>هذا ما يعرف ب ' فوبيا المرأة المتمكنة ' افة فك...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LEAP22 مؤتمر يجمع اشهر وابرز المؤثرين في المجا...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>خصوصية البيانات وحمايتها في المنظمة مطلب ولكن ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  label\n",
       "0  عشان يلمع صورته ويعنني تمكين المرأة ويصير ترند...  Negative      0\n",
       "1  روح حلل محد يم تطعيم كورونا شف الحرم البارح مل...   Neutral      1\n",
       "2  هذا ما يعرف ب ' فوبيا المرأة المتمكنة ' افة فك...  Negative      0\n",
       "3  LEAP22 مؤتمر يجمع اشهر وابرز المؤثرين في المجا...  Positive      2\n",
       "4  خصوصية البيانات وحمايتها في المنظمة مطلب ولكن ...   Neutral      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "426852fc-a6a4-460c-9037-886ca03bd76d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>لخسارة وزنك بشكل طبيعي ما الك غير مجموعة كلين ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>لا يكلف الله نفسا الا وسعها 🌹</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وكل السعوديه بدو . . حتى الحاضره منهم من اصل ب...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>المونافري طلع برهوش . . سدينا 😤</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>منو خر بيتهم مثلنا 😩</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  label\n",
       "0  لخسارة وزنك بشكل طبيعي ما الك غير مجموعة كلين ...  Negative      0\n",
       "1                      لا يكلف الله نفسا الا وسعها 🌹  Positive      2\n",
       "2  وكل السعوديه بدو . . حتى الحاضره منهم من اصل ب...  Negative      0\n",
       "3                    المونافري طلع برهوش . . سدينا 😤  Negative      0\n",
       "4                               منو خر بيتهم مثلنا 😩  Negative      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_supp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b3f2b20-87a6-4e7f-9166-0b4ed3a44f66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3502 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45273 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_text(df):\n",
    "    return tokenizer(df[\"text\"], padding=\"max_length\", max_length=128, truncation=True)\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.map(tokenize_text, batched=True)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(df_supp)\n",
    "dataset_supp = dataset_supp.map(tokenize_text, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3956359c-fe47-432f-acb8-87ea5d76b0ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_val_split = dataset.train_test_split(test_size=0.15)\n",
    "train_dataset = train_val_split[\"train\"]\n",
    "val_dataset = train_val_split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e61b8bc-663c-45a6-a774-ea29500725fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_supp_dataset = concatenate_datasets([train_dataset, train_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6113cd3-5657-45b1-bcd0-41ddb4346410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy_metric(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\"accuracy\": (labels == preds).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "168c0cb2-587c-432f-aef8-24a623689740",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() missing 1 required positional argument: 'output_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      2\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      3\u001b[0m     per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m      4\u001b[0m     per_device_eval_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m      5\u001b[0m     save_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m      6\u001b[0m     eval_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     10\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     11\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m pred: accuracy_metric(pred),\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() missing 1 required positional argument: 'output_dir'"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    save_steps=1000,\n",
    "    eval_steps=500,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset= train_supp_dataset, #train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=lambda pred: accuracy_metric(pred),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90cc0918-a01e-42a4-820b-29612c2e8c18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9622489213943481,\n",
       " 'eval_accuracy': 0.4695817490494297,\n",
       " 'eval_runtime': 3.2279,\n",
       " 'eval_samples_per_second': 162.954,\n",
       " 'eval_steps_per_second': 20.447,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53bdc018-9908-49b9-9d74-68f20310b610",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment for 'أنا أؤيد قرار الحكومة الجديدة': Neutral\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(new_tweet):\n",
    "    new_encoding = tokenizer(new_tweet, padding=\"max_length\", max_length=128, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        output = model(**new_encoding)\n",
    "    predicted_class = torch.argmax(output.logits, dim=-1).item()\n",
    "    mapping_sentiment = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
    "    if predicted_class == 0: return \"Negative\"\n",
    "    if predicted_class == 1: return \"Neutral\"\n",
    "    return \"Positive\"\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "new_tweet = \"أنا أؤيد قرار الحكومة الجديدة\"\n",
    "new_tweet = process_tweet(new_tweet)\n",
    "new_tweet = arabert_prep.preprocess(new_tweet)\n",
    "predicted_sentiment = predict_sentiment(new_tweet)\n",
    "print(f\"Predicted sentiment for '{new_tweet}': {predicted_sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5c24d4b-f580-4051-bde2-da56eb4ebd44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"../models/STL_ARABERT_TWITTER_sentiment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
