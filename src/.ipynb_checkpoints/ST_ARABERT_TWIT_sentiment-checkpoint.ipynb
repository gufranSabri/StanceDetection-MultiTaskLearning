{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4acc29-d8ec-4544-868e-a726e26b978d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import datasets\n",
    "from datasets import ClassLabel, load_dataset, Dataset, DatasetDict, concatenate_datasets\n",
    "import string\n",
    "from typing import Dict ,List\n",
    "import transformers\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AdamW\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfe92d48-4226-4e51-87e6-c23ac0de341d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/gufran/Developer/Projects/AI/MawqifStanceDetection/data\"\n",
    "MODEL_PATH = \"/Users/gufran/Developer/Projects/AI/MawqifStanceDetection/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "592da9a1-ca5c-48f1-912e-af2b16a0d3fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"aubmindlab/bert-base-arabertv02-twitter\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a8546e-1c06-4598-9bb1-001e2119d485",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ²Ù†Ùƒ Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ Ù…Ø§ Ø§Ù„Ùƒ ØºÙŠØ± Ù…Ø¬Ù…ÙˆØ¹Ø© ÙƒÙ„ÙŠÙ† ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ù„Ø§ ÙŠÙƒÙ„Ù Ø§Ù„Ù„Ù‡ Ù†ÙØ³Ø§ Ø¥Ù„Ø§ ÙˆØ³Ø¹Ù‡Ø§ ğŸŒ¹</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ÙˆÙƒÙ„ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠÙ‡ Ø¨Ø¯Ùˆ ..Ø­ØªÙ‰ Ø§Ù„Ø­Ø§Ø¶Ø±Ù‡ Ù…Ù†Ù‡Ù… Ù…Ù† Ø§ØµÙ„ Ø¨Ø¯Ùˆ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ø§Ù„Ù…ÙˆÙ†Ø§ÙØ±ÙŠ Ø·Ù„Ø¹ Ø¨Ø±Ù‡ÙˆØ´ .. Ø³Ø¯ÙŠÙ†Ø§ ğŸ˜¤</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ù…Ù†Ùˆ Ø®Ø± Ø¨ÙŠØªÙ‡Ù… Ù…Ø«Ù„Ù†Ø§ ğŸ˜©</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ²Ù†Ùƒ Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ Ù…Ø§ Ø§Ù„Ùƒ ØºÙŠØ± Ù…Ø¬Ù…ÙˆØ¹Ø© ÙƒÙ„ÙŠÙ† ...  Negative\n",
       "1                      Ù„Ø§ ÙŠÙƒÙ„Ù Ø§Ù„Ù„Ù‡ Ù†ÙØ³Ø§ Ø¥Ù„Ø§ ÙˆØ³Ø¹Ù‡Ø§ ğŸŒ¹  Positive\n",
       "2  ÙˆÙƒÙ„ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠÙ‡ Ø¨Ø¯Ùˆ ..Ø­ØªÙ‰ Ø§Ù„Ø­Ø§Ø¶Ø±Ù‡ Ù…Ù†Ù‡Ù… Ù…Ù† Ø§ØµÙ„ Ø¨Ø¯Ùˆ...  Negative\n",
       "3                     Ø§Ù„Ù…ÙˆÙ†Ø§ÙØ±ÙŠ Ø·Ù„Ø¹ Ø¨Ø±Ù‡ÙˆØ´ .. Ø³Ø¯ÙŠÙ†Ø§ ğŸ˜¤  Negative\n",
       "4                               Ù…Ù†Ùˆ Ø®Ø± Ø¨ÙŠØªÙ‡Ù… Ù…Ø«Ù„Ù†Ø§ ğŸ˜©  Negative"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_supp = pd.read_csv(os.path.join(DATA_PATH, \"ASTAD_train.csv\"))\n",
    "df_supp = df_supp[[\"text\", \"sentiment\"]]\n",
    "df_supp = df_supp.sample(frac=1, random_state=42)\n",
    "df_supp = df_supp.reset_index().drop([\"index\"], axis=1)\n",
    "df_supp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f9f3daf-10fc-431b-b629-e50d5cf953dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ø¹Ø´Ø§Ù† ÙŠÙ„Ù…Ø¹ ØµÙˆØ±ØªÙ‡ ÙˆÙŠØ¹Ù†Ù†ÙŠ ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ù…Ø±Ø£Ø© ÙˆÙŠØµÙŠØ± ØªØ±Ù†...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ø±ÙˆØ­ Ø­Ù„Ù„ Ù…Ø­Ø¯ ÙŠÙ… ØªØ·Ø¹ÙŠÙ… ÙƒÙˆØ±ÙˆÙ†Ø§ Ø´Ù Ø§Ù„Ø­Ø±Ù… Ø§Ù„Ø¨Ø§Ø±Ø­ Ù…...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ù‡Ø°Ø§ Ù…Ø§ ÙŠÙØ¹Ø±Ù‘Ù Ø¨Ù€'ÙÙˆØ¨ÙŠØ§ Ø§Ù„Ù…Ø±Ø£Ø© Ø§Ù„Ù…ÙØªÙ…ÙƒÙ†Ø©' Ø¢ÙØ© Ù...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#LEAP22  Ù…Ø¤ØªÙ…Ø± ÙŠØ¬Ù…Ø¹ Ø§Ø´Ù‡Ø± ÙˆØ§Ø¨Ø±Ø² Ø§Ù„Ù…Ø¤Ø«Ø±ÙŠÙ† ÙÙŠ Ø§Ù„Ù…...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø®ØµÙˆØµÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­Ù…Ø§ÙŠØªÙ‡Ø§ ÙÙŠ Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ù…Ø·Ù„Ø¨ ÙˆÙ„ÙƒÙ† ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0   Ø¹Ø´Ø§Ù† ÙŠÙ„Ù…Ø¹ ØµÙˆØ±ØªÙ‡ ÙˆÙŠØ¹Ù†Ù†ÙŠ ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ù…Ø±Ø£Ø© ÙˆÙŠØµÙŠØ± ØªØ±Ù†...  Negative\n",
       "1   Ø±ÙˆØ­ Ø­Ù„Ù„ Ù…Ø­Ø¯ ÙŠÙ… ØªØ·Ø¹ÙŠÙ… ÙƒÙˆØ±ÙˆÙ†Ø§ Ø´Ù Ø§Ù„Ø­Ø±Ù… Ø§Ù„Ø¨Ø§Ø±Ø­ Ù…...   Neutral\n",
       "2  Ù‡Ø°Ø§ Ù…Ø§ ÙŠÙØ¹Ø±Ù‘Ù Ø¨Ù€'ÙÙˆØ¨ÙŠØ§ Ø§Ù„Ù…Ø±Ø£Ø© Ø§Ù„Ù…ÙØªÙ…ÙƒÙ†Ø©' Ø¢ÙØ© Ù...  Negative\n",
       "3  #LEAP22  Ù…Ø¤ØªÙ…Ø± ÙŠØ¬Ù…Ø¹ Ø§Ø´Ù‡Ø± ÙˆØ§Ø¨Ø±Ø² Ø§Ù„Ù…Ø¤Ø«Ø±ÙŠÙ† ÙÙŠ Ø§Ù„Ù…...  Positive\n",
       "4  Ø®ØµÙˆØµÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­Ù…Ø§ÙŠØªÙ‡Ø§ ÙÙŠ Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ù…Ø·Ù„Ø¨ ÙˆÙ„ÙƒÙ† ...   Neutral"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"cleaned.csv\"))\n",
    "df = df[[\"text\", \"sentiment\"]]\n",
    "df = df.dropna(subset=[\"sentiment\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29fc1c62-c109-4f79-a26c-ba3da4424db8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Neutral', 'Positive'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b721a997-bd9c-498e-b6b2-12ebb98f3811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping_sentiment = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
    "df['label'] = df['sentiment'].map(lambda x: mapping_sentiment[x])\n",
    "df_supp['label'] = df_supp['sentiment'].map(lambda x: mapping_sentiment[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a11cd7a-02ef-49e0-9b53-2f0125954e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arabic_punctuations = '''`Ã·Ã—Ø›<>()*&^%][Ù€ØŒ/:\"ØŸ.,'{}~Â¦+|!â€â€¦â€œâ€“Ù€'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "\n",
    "def remove_hash_URL_MEN(text):\n",
    "    text = re.sub(r'#',' ',text)\n",
    "    text = re.sub(r'_',' ',text)\n",
    "    text = re.sub(r'URL','',text)\n",
    "    text = re.sub(r'MENTION','',text)\n",
    "    return text\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    text = re.sub(\"[Ø¥Ø¢]\", \"Ø§\", text)\n",
    "    text = re.sub(\"Ú¯\", \"Ùƒ\", text)\n",
    "    return text\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "def remove_repeating_char(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "\n",
    "def process_tweet(tweet):     \n",
    "    tweet=remove_hash_URL_MEN(tweet)\n",
    "    tweet = re.sub('@[^\\s]+', ' ', str(tweet))\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',str(tweet))    \n",
    "    tweet= normalize_arabic(str(tweet))\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
    "df.text = df.text.apply(lambda x: process_tweet(x))\n",
    "df.text = df.text.apply(lambda x: arabert_prep.preprocess(x))\n",
    "\n",
    "df_supp.text = df_supp.text.apply(lambda x: process_tweet(x))\n",
    "df_supp.text = df_supp.text.apply(lambda x: arabert_prep.preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb2fce5-cf31-43f1-b258-3a86e888f5d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ø¹Ø´Ø§Ù† ÙŠÙ„Ù…Ø¹ ØµÙˆØ±ØªÙ‡ ÙˆÙŠØ¹Ù†Ù†ÙŠ ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ù…Ø±Ø£Ø© ÙˆÙŠØµÙŠØ± ØªØ±Ù†Ø¯...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ø±ÙˆØ­ Ø­Ù„Ù„ Ù…Ø­Ø¯ ÙŠÙ… ØªØ·Ø¹ÙŠÙ… ÙƒÙˆØ±ÙˆÙ†Ø§ Ø´Ù Ø§Ù„Ø­Ø±Ù… Ø§Ù„Ø¨Ø§Ø±Ø­ Ù…Ù„...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ù‡Ø°Ø§ Ù…Ø§ ÙŠØ¹Ø±Ù Ø¨ ' ÙÙˆØ¨ÙŠØ§ Ø§Ù„Ù…Ø±Ø£Ø© Ø§Ù„Ù…ØªÙ…ÙƒÙ†Ø© ' Ø§ÙØ© ÙÙƒ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LEAP22 Ù…Ø¤ØªÙ…Ø± ÙŠØ¬Ù…Ø¹ Ø§Ø´Ù‡Ø± ÙˆØ§Ø¨Ø±Ø² Ø§Ù„Ù…Ø¤Ø«Ø±ÙŠÙ† ÙÙŠ Ø§Ù„Ù…Ø¬Ø§...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø®ØµÙˆØµÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­Ù…Ø§ÙŠØªÙ‡Ø§ ÙÙŠ Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ù…Ø·Ù„Ø¨ ÙˆÙ„ÙƒÙ† ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  label\n",
       "0  Ø¹Ø´Ø§Ù† ÙŠÙ„Ù…Ø¹ ØµÙˆØ±ØªÙ‡ ÙˆÙŠØ¹Ù†Ù†ÙŠ ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ù…Ø±Ø£Ø© ÙˆÙŠØµÙŠØ± ØªØ±Ù†Ø¯...  Negative      0\n",
       "1  Ø±ÙˆØ­ Ø­Ù„Ù„ Ù…Ø­Ø¯ ÙŠÙ… ØªØ·Ø¹ÙŠÙ… ÙƒÙˆØ±ÙˆÙ†Ø§ Ø´Ù Ø§Ù„Ø­Ø±Ù… Ø§Ù„Ø¨Ø§Ø±Ø­ Ù…Ù„...   Neutral      1\n",
       "2  Ù‡Ø°Ø§ Ù…Ø§ ÙŠØ¹Ø±Ù Ø¨ ' ÙÙˆØ¨ÙŠØ§ Ø§Ù„Ù…Ø±Ø£Ø© Ø§Ù„Ù…ØªÙ…ÙƒÙ†Ø© ' Ø§ÙØ© ÙÙƒ...  Negative      0\n",
       "3  LEAP22 Ù…Ø¤ØªÙ…Ø± ÙŠØ¬Ù…Ø¹ Ø§Ø´Ù‡Ø± ÙˆØ§Ø¨Ø±Ø² Ø§Ù„Ù…Ø¤Ø«Ø±ÙŠÙ† ÙÙŠ Ø§Ù„Ù…Ø¬Ø§...  Positive      2\n",
       "4  Ø®ØµÙˆØµÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­Ù…Ø§ÙŠØªÙ‡Ø§ ÙÙŠ Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ù…Ø·Ù„Ø¨ ÙˆÙ„ÙƒÙ† ...   Neutral      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "426852fc-a6a4-460c-9037-886ca03bd76d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ²Ù†Ùƒ Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ Ù…Ø§ Ø§Ù„Ùƒ ØºÙŠØ± Ù…Ø¬Ù…ÙˆØ¹Ø© ÙƒÙ„ÙŠÙ† ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ù„Ø§ ÙŠÙƒÙ„Ù Ø§Ù„Ù„Ù‡ Ù†ÙØ³Ø§ Ø§Ù„Ø§ ÙˆØ³Ø¹Ù‡Ø§ ğŸŒ¹</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ÙˆÙƒÙ„ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠÙ‡ Ø¨Ø¯Ùˆ . . Ø­ØªÙ‰ Ø§Ù„Ø­Ø§Ø¶Ø±Ù‡ Ù…Ù†Ù‡Ù… Ù…Ù† Ø§ØµÙ„ Ø¨...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ø§Ù„Ù…ÙˆÙ†Ø§ÙØ±ÙŠ Ø·Ù„Ø¹ Ø¨Ø±Ù‡ÙˆØ´ . . Ø³Ø¯ÙŠÙ†Ø§ ğŸ˜¤</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ù…Ù†Ùˆ Ø®Ø± Ø¨ÙŠØªÙ‡Ù… Ù…Ø«Ù„Ù†Ø§ ğŸ˜©</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  label\n",
       "0  Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ²Ù†Ùƒ Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ Ù…Ø§ Ø§Ù„Ùƒ ØºÙŠØ± Ù…Ø¬Ù…ÙˆØ¹Ø© ÙƒÙ„ÙŠÙ† ...  Negative      0\n",
       "1                      Ù„Ø§ ÙŠÙƒÙ„Ù Ø§Ù„Ù„Ù‡ Ù†ÙØ³Ø§ Ø§Ù„Ø§ ÙˆØ³Ø¹Ù‡Ø§ ğŸŒ¹  Positive      2\n",
       "2  ÙˆÙƒÙ„ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠÙ‡ Ø¨Ø¯Ùˆ . . Ø­ØªÙ‰ Ø§Ù„Ø­Ø§Ø¶Ø±Ù‡ Ù…Ù†Ù‡Ù… Ù…Ù† Ø§ØµÙ„ Ø¨...  Negative      0\n",
       "3                    Ø§Ù„Ù…ÙˆÙ†Ø§ÙØ±ÙŠ Ø·Ù„Ø¹ Ø¨Ø±Ù‡ÙˆØ´ . . Ø³Ø¯ÙŠÙ†Ø§ ğŸ˜¤  Negative      0\n",
       "4                               Ù…Ù†Ùˆ Ø®Ø± Ø¨ÙŠØªÙ‡Ù… Ù…Ø«Ù„Ù†Ø§ ğŸ˜©  Negative      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_supp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b3f2b20-87a6-4e7f-9166-0b4ed3a44f66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3502 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45273 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_text(df):\n",
    "    return tokenizer(df[\"text\"], padding=\"max_length\", max_length=128, truncation=True)\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.map(tokenize_text, batched=True)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(df_supp)\n",
    "dataset_supp = dataset_supp.map(tokenize_text, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3956359c-fe47-432f-acb8-87ea5d76b0ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_val_split = dataset.train_test_split(test_size=0.15)\n",
    "train_dataset = train_val_split[\"train\"]\n",
    "val_dataset = train_val_split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e61b8bc-663c-45a6-a774-ea29500725fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_supp_dataset = concatenate_datasets([train_dataset, train_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6113cd3-5657-45b1-bcd0-41ddb4346410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy_metric(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\"accuracy\": (labels == preds).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "168c0cb2-587c-432f-aef8-24a623689740",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() missing 1 required positional argument: 'output_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      2\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      3\u001b[0m     per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m      4\u001b[0m     per_device_eval_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m      5\u001b[0m     save_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m      6\u001b[0m     eval_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     10\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     11\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m pred: accuracy_metric(pred),\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() missing 1 required positional argument: 'output_dir'"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    save_steps=1000,\n",
    "    eval_steps=500,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset= train_supp_dataset, #train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=lambda pred: accuracy_metric(pred),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90cc0918-a01e-42a4-820b-29612c2e8c18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9622489213943481,\n",
       " 'eval_accuracy': 0.4695817490494297,\n",
       " 'eval_runtime': 3.2279,\n",
       " 'eval_samples_per_second': 162.954,\n",
       " 'eval_steps_per_second': 20.447,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53bdc018-9908-49b9-9d74-68f20310b610",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment for 'Ø£Ù†Ø§ Ø£Ø¤ÙŠØ¯ Ù‚Ø±Ø§Ø± Ø§Ù„Ø­ÙƒÙˆÙ…Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©': Neutral\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(new_tweet):\n",
    "    new_encoding = tokenizer(new_tweet, padding=\"max_length\", max_length=128, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        output = model(**new_encoding)\n",
    "    predicted_class = torch.argmax(output.logits, dim=-1).item()\n",
    "    mapping_sentiment = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
    "    if predicted_class == 0: return \"Negative\"\n",
    "    if predicted_class == 1: return \"Neutral\"\n",
    "    return \"Positive\"\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "new_tweet = \"Ø£Ù†Ø§ Ø£Ø¤ÙŠØ¯ Ù‚Ø±Ø§Ø± Ø§Ù„Ø­ÙƒÙˆÙ…Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©\"\n",
    "new_tweet = process_tweet(new_tweet)\n",
    "new_tweet = arabert_prep.preprocess(new_tweet)\n",
    "predicted_sentiment = predict_sentiment(new_tweet)\n",
    "print(f\"Predicted sentiment for '{new_tweet}': {predicted_sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5c24d4b-f580-4051-bde2-da56eb4ebd44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"../models/STL_ARABERT_TWITTER_sentiment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
