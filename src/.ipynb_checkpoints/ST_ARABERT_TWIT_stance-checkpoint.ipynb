{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4acc29-d8ec-4544-868e-a726e26b978d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import datasets\n",
    "from datasets import ClassLabel, load_dataset, Dataset, DatasetDict\n",
    "import string\n",
    "from typing import Dict ,List\n",
    "import transformers\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AdamW\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfe92d48-4226-4e51-87e6-c23ac0de341d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/gufran/Developer/Projects/AI/MawqifStanceDetection/data\"\n",
    "MODEL_PATH = \"/Users/gufran/Developer/Projects/AI/MawqifStanceDetection/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "592da9a1-ca5c-48f1-912e-af2b16a0d3fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['classifier.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"aubmindlab/bert-base-arabertv02-twitter\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f9f3daf-10fc-431b-b629-e50d5cf953dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ø¹Ø´Ø§Ù† ÙŠÙ„Ù…Ø¹ ØµÙˆØ±ØªÙ‡ ÙˆÙŠØ¹Ù†Ù†ÙŠ ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ù…Ø±Ø£Ø© ÙˆÙŠØµÙŠØ± ØªØ±Ù†...</td>\n",
       "      <td>Against</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ù‡Ø°Ø§ Ù…Ø§ ÙŠÙØ¹Ø±Ù‘Ù Ø¨Ù€'ÙÙˆØ¨ÙŠØ§ Ø§Ù„Ù…Ø±Ø£Ø© Ø§Ù„Ù…ÙØªÙ…ÙƒÙ†Ø©' Ø¢ÙØ© Ù...</td>\n",
       "      <td>Favor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#LEAP22  Ù…Ø¤ØªÙ…Ø± ÙŠØ¬Ù…Ø¹ Ø§Ø´Ù‡Ø± ÙˆØ§Ø¨Ø±Ø² Ø§Ù„Ù…Ø¤Ø«Ø±ÙŠÙ† ÙÙŠ Ø§Ù„Ù…...</td>\n",
       "      <td>Favor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø®ØµÙˆØµÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­Ù…Ø§ÙŠØªÙ‡Ø§ ÙÙŠ Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ù…Ø·Ù„Ø¨ ÙˆÙ„ÙƒÙ† ...</td>\n",
       "      <td>Favor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ÙØ®ÙˆØ±ÙŠÙ† Ø¨Ù†Ø³Ø§Ø¡ Ø§Ù„ÙˆØ·Ù† ğŸ‡¸ğŸ‡¦ ÙˆÙƒÙ„Ù†Ø§ ÙØ®Ø± Ø¨ØªÙ‚Ø¯Ù… ØªÙ…ÙƒÙŠÙ† Ø§...</td>\n",
       "      <td>Favor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   stance\n",
       "0   Ø¹Ø´Ø§Ù† ÙŠÙ„Ù…Ø¹ ØµÙˆØ±ØªÙ‡ ÙˆÙŠØ¹Ù†Ù†ÙŠ ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ù…Ø±Ø£Ø© ÙˆÙŠØµÙŠØ± ØªØ±Ù†...  Against\n",
       "2  Ù‡Ø°Ø§ Ù…Ø§ ÙŠÙØ¹Ø±Ù‘Ù Ø¨Ù€'ÙÙˆØ¨ÙŠØ§ Ø§Ù„Ù…Ø±Ø£Ø© Ø§Ù„Ù…ÙØªÙ…ÙƒÙ†Ø©' Ø¢ÙØ© Ù...    Favor\n",
       "3  #LEAP22  Ù…Ø¤ØªÙ…Ø± ÙŠØ¬Ù…Ø¹ Ø§Ø´Ù‡Ø± ÙˆØ§Ø¨Ø±Ø² Ø§Ù„Ù…Ø¤Ø«Ø±ÙŠÙ† ÙÙŠ Ø§Ù„Ù…...    Favor\n",
       "4  Ø®ØµÙˆØµÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­Ù…Ø§ÙŠØªÙ‡Ø§ ÙÙŠ Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ù…Ø·Ù„Ø¨ ÙˆÙ„ÙƒÙ† ...    Favor\n",
       "5   ÙØ®ÙˆØ±ÙŠÙ† Ø¨Ù†Ø³Ø§Ø¡ Ø§Ù„ÙˆØ·Ù† ğŸ‡¸ğŸ‡¦ ÙˆÙƒÙ„Ù†Ø§ ÙØ®Ø± Ø¨ØªÙ‚Ø¯Ù… ØªÙ…ÙƒÙŠÙ† Ø§...    Favor"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"cleaned.csv\"))\n",
    "df = df[[\"text\", \"stance\"]]\n",
    "df = df.dropna(subset=[\"stance\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b721a997-bd9c-498e-b6b2-12ebb98f3811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping_stance = {\"Favor\": 1, \"Against\": 0}\n",
    "df['label'] = df['stance'].map(lambda x: mapping_stance[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a11cd7a-02ef-49e0-9b53-2f0125954e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arabic_punctuations = '''`Ã·Ã—Ø›<>()*&^%][Ù€ØŒ/:\"ØŸ.,'{}~Â¦+|!â€â€¦â€œâ€“Ù€'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "\n",
    "def remove_hash_URL_MEN(text):\n",
    "    text = re.sub(r'#',' ',text)\n",
    "    text = re.sub(r'_',' ',text)\n",
    "    text = re.sub(r'URL','',text)\n",
    "    text = re.sub(r'MENTION','',text)\n",
    "    return text\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    text = re.sub(\"[Ø¥Ø¢]\", \"Ø§\", text)\n",
    "    text = re.sub(\"Ú¯\", \"Ùƒ\", text)\n",
    "    return text\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "def remove_repeating_char(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "\n",
    "def process_tweet(tweet):     \n",
    "    tweet=remove_hash_URL_MEN(tweet)\n",
    "    tweet = re.sub('@[^\\s]+', ' ', str(tweet))\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',str(tweet))    \n",
    "    tweet= normalize_arabic(str(tweet))\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
    "df.text = df.text.apply(lambda x: process_tweet(x))\n",
    "df.text = df.text.apply(lambda x: arabert_prep.preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfb2fce5-cf31-43f1-b258-3a86e888f5d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stance</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ø¹Ø´Ø§Ù† ÙŠÙ„Ù…Ø¹ ØµÙˆØ±ØªÙ‡ ÙˆÙŠØ¹Ù†Ù†ÙŠ ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ù…Ø±Ø£Ø© ÙˆÙŠØµÙŠØ± ØªØ±Ù†Ø¯...</td>\n",
       "      <td>Against</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ù‡Ø°Ø§ Ù…Ø§ ÙŠØ¹Ø±Ù Ø¨ ' ÙÙˆØ¨ÙŠØ§ Ø§Ù„Ù…Ø±Ø£Ø© Ø§Ù„Ù…ØªÙ…ÙƒÙ†Ø© ' Ø§ÙØ© ÙÙƒ...</td>\n",
       "      <td>Favor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LEAP22 Ù…Ø¤ØªÙ…Ø± ÙŠØ¬Ù…Ø¹ Ø§Ø´Ù‡Ø± ÙˆØ§Ø¨Ø±Ø² Ø§Ù„Ù…Ø¤Ø«Ø±ÙŠÙ† ÙÙŠ Ø§Ù„Ù…Ø¬Ø§...</td>\n",
       "      <td>Favor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø®ØµÙˆØµÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­Ù…Ø§ÙŠØªÙ‡Ø§ ÙÙŠ Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ù…Ø·Ù„Ø¨ ÙˆÙ„ÙƒÙ† ...</td>\n",
       "      <td>Favor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ÙØ®ÙˆØ±ÙŠÙ† Ø¨Ù†Ø³Ø§Ø¡ Ø§Ù„ÙˆØ·Ù† ğŸ‡¸ ğŸ‡¦ ÙˆÙƒÙ„Ù†Ø§ ÙØ®Ø± Ø¨ØªÙ‚Ø¯Ù… ØªÙ…ÙƒÙŠÙ† Ø§...</td>\n",
       "      <td>Favor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   stance  label\n",
       "0  Ø¹Ø´Ø§Ù† ÙŠÙ„Ù…Ø¹ ØµÙˆØ±ØªÙ‡ ÙˆÙŠØ¹Ù†Ù†ÙŠ ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ù…Ø±Ø£Ø© ÙˆÙŠØµÙŠØ± ØªØ±Ù†Ø¯...  Against      0\n",
       "2  Ù‡Ø°Ø§ Ù…Ø§ ÙŠØ¹Ø±Ù Ø¨ ' ÙÙˆØ¨ÙŠØ§ Ø§Ù„Ù…Ø±Ø£Ø© Ø§Ù„Ù…ØªÙ…ÙƒÙ†Ø© ' Ø§ÙØ© ÙÙƒ...    Favor      1\n",
       "3  LEAP22 Ù…Ø¤ØªÙ…Ø± ÙŠØ¬Ù…Ø¹ Ø§Ø´Ù‡Ø± ÙˆØ§Ø¨Ø±Ø² Ø§Ù„Ù…Ø¤Ø«Ø±ÙŠÙ† ÙÙŠ Ø§Ù„Ù…Ø¬Ø§...    Favor      1\n",
       "4  Ø®ØµÙˆØµÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­Ù…Ø§ÙŠØªÙ‡Ø§ ÙÙŠ Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ù…Ø·Ù„Ø¨ ÙˆÙ„ÙƒÙ† ...    Favor      1\n",
       "5  ÙØ®ÙˆØ±ÙŠÙ† Ø¨Ù†Ø³Ø§Ø¡ Ø§Ù„ÙˆØ·Ù† ğŸ‡¸ ğŸ‡¦ ÙˆÙƒÙ„Ù†Ø§ ÙØ®Ø± Ø¨ØªÙ‚Ø¯Ù… ØªÙ…ÙƒÙŠÙ† Ø§...    Favor      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b3f2b20-87a6-4e7f-9166-0b4ed3a44f66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3169 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_text(df):\n",
    "    return tokenizer(df[\"text\"], padding=\"max_length\", max_length=128, truncation=True)\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.map(tokenize_text, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3956359c-fe47-432f-acb8-87ea5d76b0ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_val_split = dataset.train_test_split(test_size=0.15)\n",
    "train_dataset = train_val_split[\"train\"]\n",
    "val_dataset = train_val_split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6113cd3-5657-45b1-bcd0-41ddb4346410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy_metric(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\"accuracy\": (labels == preds).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "168c0cb2-587c-432f-aef8-24a623689740",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3370' max='3370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3370/3370 11:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.329800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.126400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.023600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.010100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3370, training_loss=0.07307359941043955, metrics={'train_runtime': 678.0142, 'train_samples_per_second': 39.719, 'train_steps_per_second': 4.97, 'total_flos': 1771395180211200.0, 'train_loss': 0.07307359941043955, 'epoch': 10.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    save_steps=1000,\n",
    "    eval_steps=500,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=lambda pred: accuracy_metric(pred),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90cc0918-a01e-42a4-820b-29612c2e8c18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.2029073238372803,\n",
       " 'eval_accuracy': 0.8592436974789915,\n",
       " 'eval_runtime': 2.6499,\n",
       " 'eval_samples_per_second': 179.63,\n",
       " 'eval_steps_per_second': 22.642,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53bdc018-9908-49b9-9d74-68f20310b610",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted stance for 'Ø£Ù†Ø§ Ø£Ø¤ÙŠØ¯ Ù‚Ø±Ø§Ø± Ø§Ù„Ø­ÙƒÙˆÙ…Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©': Favor\n"
     ]
    }
   ],
   "source": [
    "def predict_stance(new_tweet):\n",
    "    new_encoding = tokenizer(new_tweet, padding=\"max_length\", max_length=128, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        output = model(**new_encoding)\n",
    "    predicted_class = torch.argmax(output.logits, dim=-1).item()\n",
    "    predicted_label = \"Against\" if predicted_class == 0 else \"Favor\"\n",
    "    return predicted_label\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "new_tweet = \"Ø£Ù†Ø§ Ø£Ø¤ÙŠØ¯ Ù‚Ø±Ø§Ø± Ø§Ù„Ø­ÙƒÙˆÙ…Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©\"\n",
    "new_tweet = process_tweet(new_tweet)\n",
    "new_tweet = arabert_prep.preprocess(new_tweet)\n",
    "predicted_stance = predict_stance(new_tweet)\n",
    "print(f\"Predicted stance for '{new_tweet}': {predicted_stance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5c24d4b-f580-4051-bde2-da56eb4ebd44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"../models/STL_ARABERT_TWITTER_stance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
