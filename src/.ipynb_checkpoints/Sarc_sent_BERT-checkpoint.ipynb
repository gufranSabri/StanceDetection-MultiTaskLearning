{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18a80001-1f93-4b70-be57-f3120ddfc17d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import datasets\n",
    "from datasets import ClassLabel, load_dataset, Dataset, DatasetDict\n",
    "import string\n",
    "from typing import Dict ,List\n",
    "import transformers\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c8f497-1a6d-4607-929e-26b648f055fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/gufran/Developer/Projects/AI/MawqifStanceDetection/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f78fb4-c40a-4d7a-a585-e26d6f9a8218",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"aubmindlab/bert-base-arabertv02-twitter\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "arabert_prep = ArabertPreprocessor(model_name=model_name) #keep_emojis will be automatically set to True in AraBERT-twitter.\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d274269-2a16-4f99-8715-7487263fd089",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"cleaned.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74ca8c4e-c132-4fd2-8a1f-db21cb500492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping_sent = {'Neutral': 2, 'Positive': 1, 'Negative': 0}\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: mapping_sent[x])\n",
    "\n",
    "mapping_sarcasm = {\"Yes\": 1, \"No\": 0}\n",
    "df['sarcasm'] = df['sarcasm'].apply(lambda x: mapping_sarcasm[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d7200e3-fe06-473f-8be2-842448cb71ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df[[\"text\"]]\n",
    "y = df[[\"sentiment\", \"sarcasm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d6d0ba4-e763-475c-ae3b-a84926ae9fd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lc/j4lc_54146x514qrkzhjdv740000gn/T/ipykernel_58035/663614273.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.text = X.text.apply(lambda x: process_tweet(x))\n",
      "/var/folders/lc/j4lc_54146x514qrkzhjdv740000gn/T/ipykernel_58035/663614273.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.text = X.text.apply(lambda x: arabert_prep.preprocess(x))\n"
     ]
    }
   ],
   "source": [
    "arabic_punctuations = '''`÷×؛<>()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "\n",
    "def remove_hash_URL_MEN(text):\n",
    "    text = re.sub(r'#',' ',text)\n",
    "    text = re.sub(r'_',' ',text)\n",
    "    text = re.sub(r'URL','',text)\n",
    "    text = re.sub(r'MENTION','',text)\n",
    "    return text\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    text = re.sub(\"[إآ]\", \"ا\", text)\n",
    "    #text = re.sub(\"ى\", \"ي\", text)\n",
    "    #text = re.sub(\"ة\", \"ه\", text)\n",
    "    text = re.sub(\"گ\", \"ك\", text)\n",
    "    return text\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "def remove_repeating_char(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "\n",
    "def process_tweet(tweet):     \n",
    "    tweet=remove_hash_URL_MEN(tweet)\n",
    "    tweet = re.sub('@[^\\s]+', ' ', str(tweet))\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',str(tweet))    \n",
    "    tweet= normalize_arabic(str(tweet))\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "X.text = X.text.apply(lambda x: process_tweet(x))\n",
    "X.text = X.text.apply(lambda x: arabert_prep.preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b341d433-5216-4db4-b0c7-ed7edbb9b0fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05aafb54-c8cb-4b51-aaab-155ddeec5c7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2976, 1), (2976, 2), (526, 1), (526, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6248274-32f2-4cec-b933-a5a23e629699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f60baf-2c34-4997-81b7-c487516dccd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d6f01-e38f-4bff-b61c-0301d24c4e41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
