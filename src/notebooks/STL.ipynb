{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4acc29-d8ec-4544-868e-a726e26b978d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, BertModel\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfe92d48-4226-4e51-87e6-c23ac0de341d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/gufran/Developer/Projects/AI/MawqifStanceDetection/data\"\n",
    "MODEL_PATH = \"/Users/gufran/Developer/Projects/AI/MawqifStanceDetection/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8520c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = \"sarcasm\"\n",
    "# task = \"sentiment\"\n",
    "task = \"stance\"\n",
    "\n",
    "num_labels = {\n",
    "    \"sarcasm\": 2,\n",
    "    \"sentiment\": 3,\n",
    "    \"stance\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "592da9a1-ca5c-48f1-912e-af2b16a0d3fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-da and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_models = [\n",
    "    \"aubmindlab/bert-base-arabertv02-twitter\", \n",
    "    \"aubmindlab/bert-base-arabertv02\",\n",
    "    \"UBC-NLP/MARBERT\",\n",
    "    \"CAMeL-Lab/bert-base-arabic-camelbert-da\"\n",
    "]\n",
    "\n",
    "model_name = bert_models[3]\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels[task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f9f3daf-10fc-431b-b629-e50d5cf953dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>stance</th>\n",
       "      <th>stance:confidence</th>\n",
       "      <th>against_reason</th>\n",
       "      <th>favor_reason</th>\n",
       "      <th>none_reason</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>sarcasm:confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment:confidence</th>\n",
       "      <th>datetime</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ø¹Ø´Ø§Ù† ÙŠÙ„Ù…Ø¹ ØµÙˆØ±ØªÙ‡ ÙˆÙŠØ¹Ù†Ù†ÙŠ ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ù…Ø±Ø£Ø© ÙˆÙŠØµÙŠØ± ØªØ±Ù†...</td>\n",
       "      <td>Women empowerment</td>\n",
       "      <td>Against</td>\n",
       "      <td>0.5116</td>\n",
       "      <td>A_Explicit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2021-01-16 03:19:19+00:00</td>\n",
       "      <td>16/01/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Ù‡Ø°Ø§ Ù…Ø§ ÙŠÙØ¹Ø±Ù‘Ù Ø¨Ù€'ÙÙˆØ¨ÙŠØ§ Ø§Ù„Ù…Ø±Ø£Ø© Ø§Ù„Ù…ÙØªÙ…ÙƒÙ†Ø©' Ø¢ÙØ© Ù...</td>\n",
       "      <td>Women empowerment</td>\n",
       "      <td>Favor</td>\n",
       "      <td>0.8171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F_Explicit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.8145</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>2022-04-02 07:45:42+00:00</td>\n",
       "      <td>02/04/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>#LEAP22  Ù…Ø¤ØªÙ…Ø± ÙŠØ¬Ù…Ø¹ Ø§Ø´Ù‡Ø± ÙˆØ§Ø¨Ø±Ø² Ø§Ù„Ù…Ø¤Ø«Ø±ÙŠÙ† ÙÙŠ Ø§Ù„Ù…...</td>\n",
       "      <td>Digital Transformation</td>\n",
       "      <td>Favor</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F_Explicit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7531</td>\n",
       "      <td>2022-02-02 18:24:09+00:00</td>\n",
       "      <td>02/02/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Ø®ØµÙˆØµÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­Ù…Ø§ÙŠØªÙ‡Ø§ ÙÙŠ Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ù…Ø·Ù„Ø¨ ÙˆÙ„ÙƒÙ† ...</td>\n",
       "      <td>Digital Transformation</td>\n",
       "      <td>Favor</td>\n",
       "      <td>0.7559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F_Explicit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.8116</td>\n",
       "      <td>2022-03-27 10:36:04+00:00</td>\n",
       "      <td>27/03/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>ÙØ®ÙˆØ±ÙŠÙ† Ø¨Ù†Ø³Ø§Ø¡ Ø§Ù„ÙˆØ·Ù† ğŸ‡¸ğŸ‡¦ ÙˆÙƒÙ„Ù†Ø§ ÙØ®Ø± Ø¨ØªÙ‚Ø¯Ù… ØªÙ…ÙƒÙŠÙ† Ø§...</td>\n",
       "      <td>Women empowerment</td>\n",
       "      <td>Favor</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F_Explicit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2021-03-08 14:54:45+00:00</td>\n",
       "      <td>08/03/2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               text  \\\n",
       "0   1   Ø¹Ø´Ø§Ù† ÙŠÙ„Ù…Ø¹ ØµÙˆØ±ØªÙ‡ ÙˆÙŠØ¹Ù†Ù†ÙŠ ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ù…Ø±Ø£Ø© ÙˆÙŠØµÙŠØ± ØªØ±Ù†...   \n",
       "2   4  Ù‡Ø°Ø§ Ù…Ø§ ÙŠÙØ¹Ø±Ù‘Ù Ø¨Ù€'ÙÙˆØ¨ÙŠØ§ Ø§Ù„Ù…Ø±Ø£Ø© Ø§Ù„Ù…ÙØªÙ…ÙƒÙ†Ø©' Ø¢ÙØ© Ù...   \n",
       "3   6  #LEAP22  Ù…Ø¤ØªÙ…Ø± ÙŠØ¬Ù…Ø¹ Ø§Ø´Ù‡Ø± ÙˆØ§Ø¨Ø±Ø² Ø§Ù„Ù…Ø¤Ø«Ø±ÙŠÙ† ÙÙŠ Ø§Ù„Ù…...   \n",
       "4   7  Ø®ØµÙˆØµÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­Ù…Ø§ÙŠØªÙ‡Ø§ ÙÙŠ Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ù…Ø·Ù„Ø¨ ÙˆÙ„ÙƒÙ† ...   \n",
       "5   8   ÙØ®ÙˆØ±ÙŠÙ† Ø¨Ù†Ø³Ø§Ø¡ Ø§Ù„ÙˆØ·Ù† ğŸ‡¸ğŸ‡¦ ÙˆÙƒÙ„Ù†Ø§ ÙØ®Ø± Ø¨ØªÙ‚Ø¯Ù… ØªÙ…ÙƒÙŠÙ† Ø§...   \n",
       "\n",
       "                   target   stance  stance:confidence against_reason  \\\n",
       "0       Women empowerment  Against             0.5116     A_Explicit   \n",
       "2       Women empowerment    Favor             0.8171            NaN   \n",
       "3  Digital Transformation    Favor             1.0000            NaN   \n",
       "4  Digital Transformation    Favor             0.7559            NaN   \n",
       "5       Women empowerment    Favor             1.0000            NaN   \n",
       "\n",
       "  favor_reason none_reason sarcasm  sarcasm:confidence sentiment  \\\n",
       "0          NaN         NaN      No              1.0000  Negative   \n",
       "2   F_Explicit         NaN     Yes              0.8145  Negative   \n",
       "3   F_Explicit         NaN      No              1.0000  Positive   \n",
       "4   F_Explicit         NaN      No              1.0000   Neutral   \n",
       "5   F_Explicit         NaN      No              1.0000  Positive   \n",
       "\n",
       "   sentiment:confidence                   datetime        Date  \n",
       "0                1.0000  2021-01-16 03:19:19+00:00  16/01/2021  \n",
       "2                0.8251  2022-04-02 07:45:42+00:00  02/04/2022  \n",
       "3                0.7531  2022-02-02 18:24:09+00:00  02/02/2022  \n",
       "4                0.8116  2022-03-27 10:36:04+00:00  27/03/2022  \n",
       "5                1.0000  2021-03-08 14:54:45+00:00  08/03/2021  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"Mawqif_AllTargets_Train.csv\"))\n",
    "df = df.dropna(subset=[task])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b721a997-bd9c-498e-b6b2-12ebb98f3811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping_sarcasm = {\"No\": 0, \"Yes\": 1}\n",
    "mapping_stance = {\"Favor\": 1, \"Against\": 0}\n",
    "mapping_sentiment = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
    "\n",
    "df['sarcasm'] = df['sarcasm'].map(lambda x: mapping_sarcasm[x])\n",
    "df['sentiment'] = df['sentiment'].map(lambda x: mapping_sentiment[x])\n",
    "df['stance'] = df['stance'].map(lambda x: mapping_stance[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c8c943",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"text\", task]]\n",
    "df = df.rename(columns={task: \"labels\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a11cd7a-02ef-49e0-9b53-2f0125954e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model provided is not in the accepted model list. Preprocessor will default to a base Arabic preprocessor\n"
     ]
    }
   ],
   "source": [
    "arabic_punctuations = '''`Ã·Ã—Ø›<>()*&^%][Ù€ØŒ/:\"ØŸ.,'{}~Â¦+|!â€â€¦â€œâ€“Ù€'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "\n",
    "def remove_hash_URL_MEN(text):\n",
    "    text = re.sub(r'#',' ',text)\n",
    "    text = re.sub(r'_',' ',text)\n",
    "    text = re.sub(r'URL','',text)\n",
    "    text = re.sub(r'MENTION','',text)\n",
    "    return text\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    text = re.sub(\"[Ø¥Ø¢]\", \"Ø§\", text)\n",
    "    text = re.sub(\"Ú¯\", \"Ùƒ\", text)\n",
    "    return text\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "def remove_repeating_char(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "\n",
    "def process_tweet(tweet):     \n",
    "    tweet=remove_hash_URL_MEN(tweet)\n",
    "    tweet = re.sub('@[^\\s]+', ' ', str(tweet))\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',str(tweet))    \n",
    "    tweet= normalize_arabic(str(tweet))\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
    "df.text = df.text.apply(lambda x: process_tweet(x))\n",
    "df.text = df.text.apply(lambda x: arabert_prep.preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfb2fce5-cf31-43f1-b258-3a86e888f5d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ø¹Ø´Ø§Ù† ÙŠÙ„Ù…Ø¹ ØµÙˆØ±ØªÙ‡ ÙˆÙŠØ¹Ù†Ù†ÙŠ ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ù…Ø±Ø£Ø© ÙˆÙŠØµÙŠØ± ØªØ±Ù†Ø¯...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ù‡Ø°Ø§ Ù…Ø§ ÙŠØ¹Ø±Ù Ø¨ ' ÙÙˆØ¨ÙŠØ§ Ø§Ù„Ù…Ø±Ø£Ø© Ø§Ù„Ù…ØªÙ…ÙƒÙ†Ø© ' Ø§ÙØ© ÙÙƒ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LEAP22 Ù…Ø¤ØªÙ…Ø± ÙŠØ¬Ù…Ø¹ Ø§Ø´Ù‡Ø± ÙˆØ§Ø¨Ø±Ø² Ø§Ù„Ù…Ø¤Ø«Ø±ÙŠÙ† ÙÙŠ Ø§Ù„Ù…Ø¬Ø§...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø®ØµÙˆØµÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­Ù…Ø§ÙŠØªÙ‡Ø§ ÙÙŠ Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ù…Ø·Ù„Ø¨ ÙˆÙ„ÙƒÙ† ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ÙØ®ÙˆØ±ÙŠÙ† Ø¨Ù†Ø³Ø§Ø¡ Ø§Ù„ÙˆØ·Ù† ÙˆÙƒÙ„Ù†Ø§ ÙØ®Ø± Ø¨ØªÙ‚Ø¯Ù… ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ù…Ø±Ø£...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  Ø¹Ø´Ø§Ù† ÙŠÙ„Ù…Ø¹ ØµÙˆØ±ØªÙ‡ ÙˆÙŠØ¹Ù†Ù†ÙŠ ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ù…Ø±Ø£Ø© ÙˆÙŠØµÙŠØ± ØªØ±Ù†Ø¯...       0\n",
       "2  Ù‡Ø°Ø§ Ù…Ø§ ÙŠØ¹Ø±Ù Ø¨ ' ÙÙˆØ¨ÙŠØ§ Ø§Ù„Ù…Ø±Ø£Ø© Ø§Ù„Ù…ØªÙ…ÙƒÙ†Ø© ' Ø§ÙØ© ÙÙƒ...       1\n",
       "3  LEAP22 Ù…Ø¤ØªÙ…Ø± ÙŠØ¬Ù…Ø¹ Ø§Ø´Ù‡Ø± ÙˆØ§Ø¨Ø±Ø² Ø§Ù„Ù…Ø¤Ø«Ø±ÙŠÙ† ÙÙŠ Ø§Ù„Ù…Ø¬Ø§...       1\n",
       "4  Ø®ØµÙˆØµÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­Ù…Ø§ÙŠØªÙ‡Ø§ ÙÙŠ Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ù…Ø·Ù„Ø¨ ÙˆÙ„ÙƒÙ† ...       1\n",
       "5  ÙØ®ÙˆØ±ÙŠÙ† Ø¨Ù†Ø³Ø§Ø¡ Ø§Ù„ÙˆØ·Ù† ÙˆÙƒÙ„Ù†Ø§ ÙØ®Ø± Ø¨ØªÙ‚Ø¯Ù… ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ù…Ø±Ø£...       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b3f2b20-87a6-4e7f-9166-0b4ed3a44f66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2a3fc1dd3c439c874a73fff8f39993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3169 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_text(df):\n",
    "    return tokenizer(df[\"text\"], padding=\"max_length\", max_length=128, truncation=True)\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.map(tokenize_text, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3956359c-fe47-432f-acb8-87ea5d76b0ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_val_split = dataset.train_test_split(test_size=0.15)\n",
    "train_dataset = train_val_split[\"train\"]\n",
    "val_dataset = train_val_split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e005952e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'labels', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 476\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6113cd3-5657-45b1-bcd0-41ddb4346410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy_metric(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\"accuracy\": (labels == preds).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "168c0cb2-587c-432f-aef8-24a623689740",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df139fda1e145709967bcff2d390c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6740 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5603, 'learning_rate': 4.6290801186943624e-05, 'epoch': 0.74}\n",
      "{'loss': 0.519, 'learning_rate': 4.258160237388724e-05, 'epoch': 1.48}\n",
      "{'loss': 0.6118, 'learning_rate': 3.887240356083086e-05, 'epoch': 2.23}\n",
      "{'loss': 0.6424, 'learning_rate': 3.516320474777448e-05, 'epoch': 2.97}\n",
      "{'loss': 0.6418, 'learning_rate': 3.14540059347181e-05, 'epoch': 3.71}\n",
      "{'loss': 0.6352, 'learning_rate': 2.774480712166172e-05, 'epoch': 4.45}\n",
      "{'loss': 0.6209, 'learning_rate': 2.4035608308605344e-05, 'epoch': 5.19}\n",
      "{'loss': 0.577, 'learning_rate': 2.0326409495548962e-05, 'epoch': 5.93}\n",
      "{'loss': 0.486, 'learning_rate': 1.661721068249258e-05, 'epoch': 6.68}\n",
      "{'loss': 0.4965, 'learning_rate': 1.29080118694362e-05, 'epoch': 7.42}\n",
      "{'loss': 0.5019, 'learning_rate': 9.198813056379822e-06, 'epoch': 8.16}\n",
      "{'loss': 0.5189, 'learning_rate': 5.489614243323442e-06, 'epoch': 8.9}\n",
      "{'loss': 0.4186, 'learning_rate': 1.7804154302670625e-06, 'epoch': 9.64}\n",
      "{'train_runtime': 720.7349, 'train_samples_per_second': 37.365, 'train_steps_per_second': 9.352, 'train_loss': 0.5517127424743834, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6740, training_loss=0.5517127424743834, metrics={'train_runtime': 720.7349, 'train_samples_per_second': 37.365, 'train_steps_per_second': 9.352, 'train_loss': 0.5517127424743834, 'epoch': 10.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    save_steps=1000,\n",
    "    eval_steps=500,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=lambda pred: accuracy_metric(pred),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90cc0918-a01e-42a4-820b-29612c2e8c18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe7c5af2f314fe6ba7f3c224e455692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7906274199485779,\n",
       " 'eval_accuracy': 0.8067226890756303,\n",
       " 'eval_runtime': 2.4487,\n",
       " 'eval_samples_per_second': 194.389,\n",
       " 'eval_steps_per_second': 24.503,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(\"mps\")\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53bdc018-9908-49b9-9d74-68f20310b610",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted stance for 'Ø£Ù†Ø§ Ø£Ø¤ÙŠØ¯ Ù‚Ø±Ø§Ø± Ø§Ù„Ø­ÙƒÙˆÙ…Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©': Yes\n"
     ]
    }
   ],
   "source": [
    "def predict_sarcasm(new_tweet):\n",
    "    new_encoding = tokenizer(new_tweet, padding=\"max_length\", max_length=128, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        output = model(**new_encoding)\n",
    "    predicted_class = torch.argmax(output.logits, dim=-1).item()\n",
    "    if predicted_class == 0: return \"No\"\n",
    "    return \"Yes\"\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "new_tweet = \"Ø£Ù†Ø§ Ø£Ø¤ÙŠØ¯ Ù‚Ø±Ø§Ø± Ø§Ù„Ø­ÙƒÙˆÙ…Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©\"\n",
    "new_tweet = process_tweet(new_tweet)\n",
    "new_tweet = arabert_prep.preprocess(new_tweet)\n",
    "predicted_sarcasm = predict_sarcasm(new_tweet)\n",
    "print(f\"Predicted {task} for '{new_tweet}': {predicted_sarcasm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5c24d4b-f580-4051-bde2-da56eb4ebd44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model(f\"../models/STL_ARABERT_TWITTER_{task}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
