{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b46c978-1d90-488c-87a6-4c4aafca3258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import datasets\n",
    "from datasets import ClassLabel, load_dataset, Dataset, DatasetDict\n",
    "import string\n",
    "from typing import Dict ,List\n",
    "import transformers\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AdamW\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8122340-3e18-4027-90c7-dc4e997b1029",
   "metadata": {},
   "source": [
    "<h2 style='color:red'>NOTE: change all occurrences of MPS to CUDA if not training on macOS</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39c6f73-5b10-4f85-8e87-e79746c3ef08",
   "metadata": {},
   "source": [
    "## SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197434b1-87c5-4482-af6c-78f257b61653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/gufran/Developer/Projects/AI/MawqifStanceDetection/data\"\n",
    "MODEL_PATH = \"/Users/gufran/Developer/Projects/AI/MawqifStanceDetection/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4ca67e7-48db-42d3-b0ef-e9303d91b54a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_gnn = True\n",
    "num_msg_passing = 1\n",
    "concatenate_msg_bert = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "534e08fc-6def-4724-ad44-758de0fa25d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = \"all\"\n",
    "#target = 'Covid Vaccine'\n",
    "#target = 'Digital Transformation'\n",
    "#target = 'Women empowerment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dedacaef-76a4-498b-b55f-915afa9bef5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"aubmindlab/bert-base-arabertv02-twitter\"\n",
    "# model_name = \"aubmindlab/bert-base-arabertv02\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9340d89f-dfc3-412c-8e66-2106a254e546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 20\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 1e-5\n",
    "dropout = 0.1\n",
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9654aca4-26e6-45a8-bf9b-3649569514b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "#FOR MAC --------------------------------------------\n",
    "torch.mps.manual_seed(seed)\n",
    "torch.backends.mps.deterministic=True\n",
    "torch.backends.mps.benchmark = False\n",
    "\n",
    "#FOR WINDOWS AND LINUX -------------------------------\n",
    "# torch.cuda.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed)\n",
    "# torch.backends.cudnn.deterministic=True #replace mps with cudnn here\n",
    "# torch.backends.cudnn.benchmark = False #replace mps with cudnn here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4784b50c-ee68-4d5d-bdec-76979a5b6b43",
   "metadata": {},
   "source": [
    "## DATA LOADING AND PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee9b48ab-6b6a-4452-aba8-d8e7681f157a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stance</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>والوزارة كل يوم مغردين عن التحول الرقمي والت...</td>\n",
       "      <td>No</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Favor</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>تمكين المرأة يعني فتح المجال لها للعمل في مجال...</td>\n",
       "      <td>No</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Favor</td>\n",
       "      <td>0.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MENTION تمكين المرأة السعودية ورحلة كفاحها هو ...</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Favor</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>هذا الدراسه العالميه الحديثه التي تعاون و شارك...</td>\n",
       "      <td>No</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Favor</td>\n",
       "      <td>0.7029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>نحن نتعرض لحملة موافقة اجبارية ممنهجة😅 ماتلاحظ...</td>\n",
       "      <td>No</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Against</td>\n",
       "      <td>0.6823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sarcasm sentiment  \\\n",
       "0    والوزارة كل يوم مغردين عن التحول الرقمي والت...      No   Neutral   \n",
       "1  تمكين المرأة يعني فتح المجال لها للعمل في مجال...      No   Neutral   \n",
       "2  MENTION تمكين المرأة السعودية ورحلة كفاحها هو ...      No  Positive   \n",
       "3  هذا الدراسه العالميه الحديثه التي تعاون و شارك...      No   Neutral   \n",
       "4  نحن نتعرض لحملة موافقة اجبارية ممنهجة😅 ماتلاحظ...      No   Neutral   \n",
       "\n",
       "    stance  sentiment_confidence  \n",
       "0    Favor                1.0000  \n",
       "1    Favor                0.6667  \n",
       "2    Favor                1.0000  \n",
       "3    Favor                0.7029  \n",
       "4  Against                0.6823  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"cleaned.csv\"))\n",
    "df = df.dropna(subset=[\"stance\"])\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df = df[[\"text\", \"sarcasm\", \"sentiment\", \"stance\", \"sentiment_confidence\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1a9a0e9-9122-454a-b4e7-2087af28eca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping_sarcasm = {\"No\": 0, \"Yes\": 1}\n",
    "df['sarcasm'] = df['sarcasm'].map(lambda x: mapping_sarcasm[x])\n",
    "\n",
    "mapping_sentiment = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
    "df['sentiment'] = df['sentiment'].map(lambda x: mapping_sentiment[x])\n",
    "\n",
    "mapping_stance = {\"Favor\": 1, \"Against\": 0}\n",
    "df['stance'] = df['stance'].map(lambda x: mapping_stance[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "829e4180-e0d2-4ea3-a3a6-43a76cb04eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_punctuations = '''`÷×؛<>()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "\n",
    "def remove_hash_URL_MEN(text):\n",
    "    text = re.sub(r'#',' ',text)\n",
    "    text = re.sub(r'_',' ',text)\n",
    "    text = re.sub(r'URL','',text)\n",
    "    text = re.sub(r'MENTION','',text)\n",
    "    return text\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    text = re.sub(\"[إآ]\", \"ا\", text)\n",
    "    text = re.sub(\"گ\", \"ك\", text)\n",
    "    return text\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "def remove_repeating_char(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "\n",
    "def process_tweet(tweet):     \n",
    "    tweet=remove_hash_URL_MEN(tweet)\n",
    "    tweet = re.sub('@[^\\s]+', ' ', str(tweet))\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',str(tweet))    \n",
    "    tweet= normalize_arabic(str(tweet))\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
    "df.text = df.text.apply(lambda x: process_tweet(x))\n",
    "df.text = df.text.apply(lambda x: arabert_prep.preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ab11eb2-8320-45df-9eb7-7dc30774af85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stance</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>والوزارة كل يوم مغردين عن التحول الرقمي والتعل...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>تمكين المرأة يعني فتح المجال لها للعمل في مجال...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>تمكين المرأة السعودية ورحلة كفاحها هو الانتصار</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>هذا الدراسه العالميه الحديثه التي تعاون و شارك...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>نحن نتعرض لحملة موافقة اجبارية ممنهجة 😅 ماتلاح...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sarcasm  sentiment  \\\n",
       "0  والوزارة كل يوم مغردين عن التحول الرقمي والتعل...        0          1   \n",
       "1  تمكين المرأة يعني فتح المجال لها للعمل في مجال...        0          1   \n",
       "2     تمكين المرأة السعودية ورحلة كفاحها هو الانتصار        0          2   \n",
       "3  هذا الدراسه العالميه الحديثه التي تعاون و شارك...        0          1   \n",
       "4  نحن نتعرض لحملة موافقة اجبارية ممنهجة 😅 ماتلاح...        0          1   \n",
       "\n",
       "   stance  sentiment_confidence  \n",
       "0       1                1.0000  \n",
       "1       1                0.6667  \n",
       "2       1                1.0000  \n",
       "3       1                0.7029  \n",
       "4       0                0.6823  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0c3be2d-9402-42ca-8df2-1a0d0d8076e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df[[\"text\" , \"sentiment_confidence\"]]\n",
    "y = df[[\"sarcasm\", \"sentiment\", \"stance\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e8f5e7d-6b5b-42b1-9355-fd465d3f4e84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2693, 1) y_train shape: (2693, 3) X_test shape: (476, 1) y_test shape: (476, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# rows_to_keep = X_train['sentiment_confidence'] >= 0.6\n",
    "# X_train = X_train[rows_to_keep]\n",
    "# y_train = y_train[rows_to_keep]\n",
    "\n",
    "X_train = X_train[[\"text\"]]\n",
    "X_test = X_test[[\"text\"]]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape, \"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1c209bc-c448-4e01-8e90-6797a90e4fa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_text(text):\n",
    "    return tokenizer(text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "encoded_tweets_train = [encode_text(text) for text in X_train[\"text\"]]\n",
    "encoded_tweets_test = [encode_text(text) for text in X_test[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9907e689-c3fd-4ab7-a94a-4a12901fb062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(encoded_tweets, labels):    \n",
    "    main_tweets, context_tweets, sentiments, sarcasms, stances = [], [], [], [], []\n",
    "    len_encoded_tweets = len(encoded_tweets)\n",
    "    \n",
    "    for i in range(len_encoded_tweets):\n",
    "        context_tweet_index = random.randint(0, len_encoded_tweets-1)\n",
    "        main_tweets.append(encoded_tweets[i])\n",
    "        context_tweets.append(encoded_tweets[context_tweet_index])\n",
    "\n",
    "        sentiments.append(labels.sentiment.iloc[i])\n",
    "        sarcasms.append(labels.sarcasm.iloc[i])\n",
    "        stances.append(labels.stance.iloc[i])\n",
    "            \n",
    "    return main_tweets, context_tweets, sentiments, sarcasms, stances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a1409f3-1c40-46ec-af6e-f77898147f04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_tweets, context_tweets, sentiments, sarcasms, stances = data_generator(encoded_tweets_train, y_train)\n",
    "train_dataset = TensorDataset(\n",
    "    torch.cat([item[\"input_ids\"] for item in main_tweets]),\n",
    "    torch.cat([item[\"attention_mask\"] for item in main_tweets]),\n",
    "    torch.cat([item[\"input_ids\"] for item in context_tweets]),\n",
    "    torch.cat([item[\"attention_mask\"] for item in context_tweets]),\n",
    "    torch.tensor(sarcasms),\n",
    "    torch.tensor(sentiments),\n",
    "    torch.tensor(stances),\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "main_tweets, context_tweets, sentiments, sarcasms, stances = data_generator(encoded_tweets_test, y_test)\n",
    "val_dataset = TensorDataset(\n",
    "    torch.cat([item[\"input_ids\"] for item in main_tweets]),\n",
    "    torch.cat([item[\"attention_mask\"] for item in main_tweets]),\n",
    "    torch.cat([item[\"input_ids\"] for item in context_tweets]),\n",
    "    torch.cat([item[\"attention_mask\"] for item in context_tweets]),\n",
    "    torch.tensor(sarcasms),\n",
    "    torch.tensor(sentiments),\n",
    "    torch.tensor(stances),\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61f5bcbf-eb8b-4d64-8431-8b7faff417db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sarcasm_labels = len(df.sarcasm.unique())\n",
    "num_sentiment_labels = len(df.sentiment.unique())\n",
    "num_stance_labels = len(df.stance.unique())\n",
    "\n",
    "num_sarcasm_labels, num_sentiment_labels, num_stance_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b987a76c-5bc9-4967-ad1e-4525d02515ea",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8436701-67d5-40f9-bf93-ebc3290befc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MODEL ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fb3f629-18d4-4bbb-b6d4-adb7fbdcd1bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SubTaskHead(nn.Module):\n",
    "    def __init__(self, num_labels, hidden_size):\n",
    "        super(SubTaskHead, self).__init__()\n",
    "        \n",
    "        self.num_labels = num_labels\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        logits = F.dropout(inputs, p=dropout, training=self.training)\n",
    "        logits = self.classifier(logits)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        self.classifier.weight.data.normal_(mean=0.0, std=0.02)\n",
    "        if self.classifier.bias is not None:\n",
    "            self.classifier.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a211e77d-4422-4806-b4eb-5184df5692d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StanceHead(torch.nn.Module):\n",
    "    def __init__(self, last_hidden_state_size, hidden_channels, num_classes, concatenate_msg_bert = True):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(last_hidden_state_size, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.concatenate_msg_bert = concatenate_msg_bert\n",
    "        \n",
    "        self.classifier = nn.Linear(hidden_channels if not concatenate_msg_bert else hidden_channels + last_hidden_state_size, num_classes)\n",
    "\n",
    "    def forward(self, mt_last_hidden_state, sentiments, sarcasms):\n",
    "        node_features = torch.tensor(mt_last_hidden_state, dtype=torch.float)\n",
    "\n",
    "        edges = []\n",
    "        edge_features = []\n",
    "        for i in range(len(sentiments)):\n",
    "            for j in range(len(sentiments)):\n",
    "                if i == j: continue\n",
    "                if sentiments[i] == sentiments[j] or sarcasms[i] == sarcasms[j]:\n",
    "                    edges.append((i, j))\n",
    "                    if sentiments[i] == sentiments[j] and sarcasms[i] == sarcasms[j]:\n",
    "                        edge_features.append(1.0)\n",
    "                    else:\n",
    "                        edge_features.append(0.5)\n",
    "\n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_features, dtype=torch.float)\n",
    "        data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr).to(device)\n",
    "\n",
    "        x = self.conv1(data.x, data.edge_index, data.edge_attr)\n",
    "        x = F.tanh(x)\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "\n",
    "        if num_msg_passing == 2:\n",
    "            x = self.conv2(x, data.edge_index, data.edge_attr)\n",
    "            x = x.relu()\n",
    "            x = F.dropout(x, p=dropout, training=self.training)\n",
    "\n",
    "        if num_msg_passing == 3:\n",
    "            x = self.conv3(x, data.edge_index, data.edge_attr)\n",
    "            x = x.relu()\n",
    "            x = F.dropout(x, p=dropout, training=self.training)\n",
    "\n",
    "        if self.concatenate_msg_bert:\n",
    "            x = torch.cat((x, data.x), dim=-1)\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        self.classifier.weight.data.normal_(mean=0.0, std=0.02)\n",
    "        if self.classifier.bias is not None:\n",
    "            self.classifier.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c772d61-1c37-47ff-812f-2272fefe2be7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, bert, sentiment_head, sarcasm_head, stance_head, subtask_hidden_layer_size):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "\n",
    "        self.bert = bert\n",
    "        self.hidden_layer = nn.Linear(bert.config.hidden_size, subtask_hidden_layer_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.sentiment_head = sentiment_head\n",
    "        self.sarcasm_head = sarcasm_head\n",
    "        self.stance_head = stance_head\n",
    "        \n",
    "    def forward(self, mt_input_ids, mt_attention_mask, ct_input_ids, ct_attention_mask):\n",
    "        mt_outputs = self.bert(input_ids=mt_input_ids, attention_mask=mt_attention_mask)\n",
    "        ct_outputs = self.bert(input_ids=ct_input_ids, attention_mask=ct_attention_mask)\n",
    "                \n",
    "        mt_last_hidden_state = mt_outputs.last_hidden_state[:, 0, :]\n",
    "        ct_last_hidden_state = ct_outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        hidden_output = self.dropout(F.relu(self.hidden_layer(mt_last_hidden_state)))\n",
    "        sarcasm_logits = self.sarcasm_head(hidden_output)\n",
    "        sentiment_logits = self.sentiment_head(hidden_output)\n",
    "        \n",
    "        sentiments = sentiment_logits.argmax(axis=1)\n",
    "        sarcasms = sarcasm_logits.argmax(axis=1)\n",
    "        if use_gnn: stance_logits = self.stance_head(mt_last_hidden_state, sentiments, sarcasms)\n",
    "        else: stance_logits = self.stance_head(hidden_output)\n",
    "        \n",
    "        return sarcasm_logits, sentiment_logits, stance_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576e077a-c20c-40b1-b374-a71249e27cf6",
   "metadata": {},
   "source": [
    "## TRAINING & VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4524f0a2-78dd-4f07-9fc7-db364afa7003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LinearDecayLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, n_epoch, start_decay, last_epoch=-1):\n",
    "        self.start_decay=start_decay\n",
    "        self.n_epoch=n_epoch\n",
    "        super(LinearDecayLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        last_epoch = self.last_epoch\n",
    "        n_epoch=self.n_epoch\n",
    "        b_lr=self.base_lrs[0]\n",
    "        start_decay=self.start_decay\n",
    "        if last_epoch>start_decay:\n",
    "            lr=b_lr-b_lr/(n_epoch-start_decay)*(last_epoch-start_decay)\n",
    "        else:\n",
    "            lr=b_lr\n",
    "        return [lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "183394a0-43d4-40f0-b3e4-cfdfc13a130d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 || Learning Rate: [2e-05]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992449d9b8004f9ca28b480c0051ed9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/169 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 768])\n",
      "torch.Size([16, 768])\n",
      "torch.Size([16, 768])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m stance_y \u001b[38;5;241m=\u001b[39m stance_y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     42\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 43\u001b[0m sarcasm_logits, sentiment_logits, stance_logits \u001b[38;5;241m=\u001b[39m model(mt_input_ids, mt_attention_mask, ct_input_ids, ct_attention_mask)\n\u001b[1;32m     45\u001b[0m sarcasm_loss \u001b[38;5;241m=\u001b[39m ce_loss(sarcasm_logits, sarc_y)\n\u001b[1;32m     46\u001b[0m sentiment_loss \u001b[38;5;241m=\u001b[39m ce_loss(sentiment_logits, sent_y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1510\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1517\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 26\u001b[0m, in \u001b[0;36mMultiTaskModel.forward\u001b[0;34m(self, mt_input_ids, mt_attention_mask, ct_input_ids, ct_attention_mask)\u001b[0m\n\u001b[1;32m     24\u001b[0m sentiments \u001b[38;5;241m=\u001b[39m sentiment_logits\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     25\u001b[0m sarcasms \u001b[38;5;241m=\u001b[39m sarcasm_logits\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_gnn: stance_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstance_head(mt_last_hidden_state, sentiments, sarcasms)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: stance_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstance_head(hidden_output)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sarcasm_logits, sentiment_logits, stance_logits\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1510\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1517\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 23\u001b[0m, in \u001b[0;36mStanceHead.forward\u001b[0;34m(self, mt_last_hidden_state, sentiments, sarcasms)\u001b[0m\n\u001b[1;32m     21\u001b[0m edges\u001b[38;5;241m.\u001b[39mappend((i, j))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sentiments[i] \u001b[38;5;241m==\u001b[39m sentiments[j] \u001b[38;5;129;01mand\u001b[39;00m sarcasms[i] \u001b[38;5;241m==\u001b[39m sarcasms[j]:\n\u001b[0;32m---> 23\u001b[0m     edge_features\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     edge_features\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m0.5\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "subtask_hidden_layer_size = 256\n",
    "gnn_hidden_layer_size = 256\n",
    "bert_emb_size = bert.config.hidden_size\n",
    "\n",
    "stance_head = StanceHead(bert_emb_size, gnn_hidden_layer_size, num_stance_labels, concatenate_msg_bert = concatenate_msg_bert) if use_gnn else SubTaskHead(num_stance_labels, subtask_hidden_layer_size) \n",
    "model = MultiTaskModel(\n",
    "    bert,\n",
    "    SubTaskHead(num_sentiment_labels, subtask_hidden_layer_size),\n",
    "    SubTaskHead(num_sarcasm_labels, subtask_hidden_layer_size),\n",
    "    stance_head,\n",
    "    subtask_hidden_layer_size,\n",
    ").to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "lr_scheduler=LinearDecayLR(optimizer, num_epochs, int(num_epochs*0.75))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1} || Learning Rate: {lr_scheduler.get_lr()}\")\n",
    "    \n",
    "    # TRAINING -------------------------------------------------------------------------------\n",
    "    model.train()\n",
    "    train_loader_gen = data_generator(encoded_tweets_train, y_train)\n",
    "    valid_loader_gen = data_generator(encoded_tweets_test, y_test)\n",
    "    \n",
    "    epoch_sarcasm_loss, epoch_sentiment_loss, epoch_stance_loss = 0.0, 0.0, 0.0    \n",
    "    correct_sarcasm, correct_sentiment, correct_stance, total_samples = 0,0,0,0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        mt_input_ids, mt_attention_mask, ct_input_ids, ct_attention_mask, sarc_y, sent_y, stance_y = batch\n",
    "        mt_input_ids = mt_input_ids.to(device)\n",
    "        mt_attention_mask = mt_attention_mask.to(device)\n",
    "        ct_input_ids = ct_input_ids.to(device)\n",
    "        ct_attention_mask = ct_attention_mask.to(device)\n",
    "\n",
    "        sarc_y = sarc_y.to(device)\n",
    "        sent_y = sent_y.to(device)\n",
    "        stance_y = stance_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        sarcasm_logits, sentiment_logits, stance_logits = model(mt_input_ids, mt_attention_mask, ct_input_ids, ct_attention_mask)\n",
    "\n",
    "        sarcasm_loss = ce_loss(sarcasm_logits, sarc_y)\n",
    "        sentiment_loss = ce_loss(sentiment_logits, sent_y)\n",
    "        stance_loss = ce_loss(stance_logits, stance_y)\n",
    "\n",
    "        total_loss = sarcasm_loss + sentiment_loss + stance_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        correct_sarcasm += (sarcasm_logits.argmax(dim=1) == sarc_y).sum().item()\n",
    "        correct_sentiment += (sentiment_logits.argmax(dim=1) == sent_y).sum().item()\n",
    "        correct_stance += (stance_logits.argmax(dim=1) == stance_y).sum().item()\n",
    "        total_samples += mt_input_ids.size(0)\n",
    "\n",
    "        epoch_sarcasm_loss += sarcasm_loss.item()\n",
    "        epoch_sentiment_loss += sentiment_loss.item()\n",
    "        epoch_stance_loss += stance_loss.item()\n",
    "           \n",
    "    avg_sarcasm_loss = epoch_sarcasm_loss / total_samples\n",
    "    avg_sentiment_loss = epoch_sentiment_loss / total_samples\n",
    "    avg_stance_loss = epoch_stance_loss / total_samples\n",
    "\n",
    "    sarcasm_acc = correct_sarcasm / total_samples\n",
    "    sentiment_acc = correct_sentiment / total_samples\n",
    "    stance_acc = correct_stance / total_samples\n",
    "\n",
    "    print(f\"Sarcasm -> Loss: {avg_sarcasm_loss:.4f}, Acc: {sarcasm_acc:.4f}\")\n",
    "    print(f\"Sentiment -> Loss: {avg_sentiment_loss:.4f}, Acc: {sentiment_acc:.4f}\")\n",
    "    print(f\"Stance -> Loss: {avg_stance_loss:.4f}, Acc: {stance_acc:.4f}\")\n",
    "    \n",
    "    \n",
    "    # VALIDATION -------------------------------------------------------------------------------\n",
    "    model.eval()\n",
    "    valid_sarcasm_loss, valid_sentiment_loss, valid_stance_loss = 0.0, 0.0, 0.0\n",
    "    valid_correct_sarcasm, valid_correct_sentiment, valid_correct_stance, valid_total_samples = 0,0,0,0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "            mt_input_ids, mt_attention_mask, ct_input_ids, ct_attention_mask, sarc_y, sent_y, stance_y = batch\n",
    "            mt_input_ids = mt_input_ids.to(device)\n",
    "            mt_attention_mask = mt_attention_mask.to(device)\n",
    "            ct_input_ids = ct_input_ids.to(device)\n",
    "            ct_attention_mask = ct_attention_mask.to(device)\n",
    "\n",
    "            sarc_y = sarc_y.to(device)\n",
    "            sent_y = sent_y.to(device)\n",
    "            stance_y = stance_y.to(device)\n",
    "\n",
    "            sarcasm_logits, sentiment_logits, stance_logits = model(mt_input_ids, mt_attention_mask, ct_input_ids, ct_attention_mask)\n",
    "\n",
    "            sarcasm_loss = ce_loss(sarcasm_logits, sarc_y)\n",
    "            sentiment_loss = ce_loss(sentiment_logits, sent_y)\n",
    "            stance_loss = ce_loss(stance_logits, stance_y)\n",
    "\n",
    "            valid_sarcasm_loss += sarcasm_loss.item()\n",
    "            valid_sentiment_loss += sentiment_loss.item()\n",
    "            valid_stance_loss += stance_loss.item()\n",
    "\n",
    "            valid_correct_sarcasm += (sarcasm_logits.argmax(dim=1) == sarc_y).sum().item()\n",
    "            valid_correct_sentiment += (sentiment_logits.argmax(dim=1) == sent_y).sum().item()\n",
    "            valid_correct_stance += (stance_logits.argmax(dim=1) == stance_y).sum().item()\n",
    "            valid_total_samples += mt_input_ids.size(0)\n",
    "    \n",
    "    avg_valid_sarcasm_loss = valid_sarcasm_loss / valid_total_samples\n",
    "    avg_valid_sentiment_loss = valid_sentiment_loss / valid_total_samples\n",
    "    avg_valid_stance_loss = valid_stance_loss / valid_total_samples\n",
    "    \n",
    "    valid_sarcasm_acc = valid_correct_sarcasm / valid_total_samples\n",
    "    valid_sentiment_acc = valid_correct_sentiment / valid_total_samples\n",
    "    valid_stance_acc = valid_correct_stance / valid_total_samples\n",
    "\n",
    "    print(f\"Sarcasm -> Loss: {avg_valid_sarcasm_loss:.4f}, Acc: {valid_sarcasm_acc:.4f}\")\n",
    "    print(f\"Sentiment -> Loss: {avg_valid_sentiment_loss:.4f}, Acc: {valid_sentiment_acc:.4f}\")\n",
    "    print(f\"Stance -> Loss: {avg_valid_stance_loss:.4f}, Acc: {valid_stance_acc:.4f}\\n\\n\")\n",
    "    \n",
    "    lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc100b7-9cb5-47de-a4d1-0b08cc0d40f7",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc70317-ec6b-44d8-a293-78236ab74c07",
   "metadata": {},
   "source": [
    "highest 89.71"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
